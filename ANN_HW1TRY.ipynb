{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab04c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4183086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 243 entries, 0 to 242\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       243 non-null    object \n",
      " 1   Open       243 non-null    float64\n",
      " 2   High       243 non-null    float64\n",
      " 3   Low        243 non-null    float64\n",
      " 4   Close      243 non-null    float64\n",
      " 5   Adj Close  243 non-null    float64\n",
      " 6   Volume     243 non-null    int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 13.4+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 讀取資料\n",
    "df = pd.read_csv('0050.TW.csv')\n",
    "df = df.round(3)\n",
    "# df.index = list(map(lambda x:datetime.datetime.strptime(x, '%Y-%m-%d'), df.index))\n",
    "\n",
    "# 设置显示选项\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "torch.set_printoptions(profile='full')\n",
    "\n",
    "df.info()\n",
    "\n",
    "# # 設定要使用的特徵\n",
    "# features = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "\n",
    "# print(df)\n",
    "# timeseries = df[features].values.round(3)\n",
    "\n",
    "# print(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed50b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c319968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "timeseries = df[['Open', 'High', 'Low', 'Adj Close', 'Volume','Close']].values.astype('float32')\n",
    "input_size = timeseries.shape[-1]\n",
    "print(input_size)\n",
    "# 一定要先將資料標準化，不然loss值會過大導致無法收斂，且預測值全部變成同一個數\n",
    "# scaler\n",
    "scaler = StandardScaler()\n",
    "timeseries = scaler.fit_transform(timeseries)\n",
    "\n",
    "# train-val split for time series\n",
    "train_size = int(len(timeseries) * 0.67)\n",
    "test_size = len(timeseries) - train_size\n",
    "train, val = timeseries[:train_size], timeseries[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0eccdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([157, 5, 6]) torch.Size([157, 1])\n",
      "torch.Size([76, 5, 6]) torch.Size([76, 1])\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(dataset, lookback):\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset)-lookback):\n",
    "        feature = dataset[i:i+lookback, :]\n",
    "        target = dataset[i+1:i+lookback+1][-1][-1]\n",
    "\n",
    "        # 只使用收盤價作為input\n",
    "        # feature = dataset[i:i+lookback]\n",
    "        # target = dataset[i+1:i+lookback+1][-1]\n",
    "\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(X), torch.tensor(y).view(-1, 1)\n",
    "\n",
    "lookback = 5\n",
    "X_train, y_train = create_dataset(train, lookback=lookback)\n",
    "X_val, y_val = create_dataset(val, lookback=lookback)\n",
    "print(X_train.size(), y_train.size())\n",
    "print(X_val.size(), y_val.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0dd8f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size=64, num_layers=2, batch_first = True)\n",
    "        self.linear = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08d46766",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_Model()\n",
    "# optimizer = optim.Adam(model.parameters())\n",
    "# 使用SDG或Adam演算法的lstm經常會用RMSprop做為優化方向，因為，它收斂的速度會比較快，原因是RMSprop 的學習速率(learning rate)會隨著之前的梯度總和作反向的調整。\n",
    "optimizer = optim.RMSprop(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "n_epochs = 300\n",
    "\n",
    "loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=False, batch_size=8)\n",
    "train_loss_array = []\n",
    "val_loss_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf5d626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train_loss 0.3458, val_loss 1.9592\n",
      "Epoch 100: train_loss 0.0149, val_loss 3.4015\n",
      "Epoch 200: train_loss 0.0031, val_loss 2.3523\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 確認loss值的變化正常\n",
    "    # if epoch % 100 ==0:\n",
    "    #     print(y_pred)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_train)\n",
    "        # train_rmse = np.sqrt(loss_fn(y_pred, y_train))\n",
    "        train_loss = loss_fn(y_pred, y_train).item()\n",
    "\n",
    "        y_pred = model(X_val)\n",
    "        # test_rmse = np.sqrt(loss_fn(y_pred, y_test))\n",
    "        val_loss = loss_fn(y_pred, y_val).item()\n",
    "\n",
    "        train_loss_array.append(train_loss)\n",
    "        val_loss_array.append(val_loss)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch %d: train_loss %.4f, val_loss %.4f\" % (epoch, train_loss, val_loss))\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    # shift train predictions for plotting\n",
    "    # 因為timeseries包含開、高、低、收等資料，因此需要timeseries[:, -1]取得最後一項 收盤價 的欄位長度即可\n",
    "    train_plot = np.ones_like(timeseries[:, -1]) * np.nan\n",
    "    y_pred = model(X_train)\n",
    "    # train_plot.shape == (len(X_train), )為一維矩陣，model(X_train).size == (len(X_train), 1)為二維矩陣，因此需要view()\n",
    "    train_plot[lookback:train_size] = model(X_train).view(-1)\n",
    "\n",
    "    # shift test predictions for plotting\n",
    "    test_plot = np.ones_like(timeseries[:,-1]) * np.nan\n",
    "    test_plot[train_size+lookback:len(timeseries)] = model(X_val).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c2a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# 因為timeseries包含開、高、低、收等資料，因此需要timeseries[:, -1]取得最後一項 收盤價 的欄位資料即可\n",
    "plt.plot(timeseries[:, -1])\n",
    "plt.plot(train_plot)\n",
    "plt.plot(test_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1020ffcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3bdb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
