{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "535dcd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "f21eae8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Open    High     Low   Close  Adj Close    Volume\n",
      "2023-03-21  118.50  118.75  118.20  118.65  114.277    3591870 \n",
      "2023-03-22  119.45  120.90  119.45  120.90  116.444    14242127\n",
      "2023-03-23  120.65  122.30  120.45  121.85  117.359    15532979\n",
      "2023-03-24  122.00  122.30  121.55  122.20  117.696    13457394\n",
      "2023-03-27  121.75  121.90  121.20  121.45  116.974    10644595\n",
      "...            ...     ...     ...     ...      ...         ...\n",
      "2024-03-14  154.90  155.80  154.30  155.10  155.100    8318618 \n",
      "2024-03-15  154.30  154.75  153.00  153.00  153.000    8600954 \n",
      "2024-03-18  153.00  154.50  153.00  154.40  154.400    17937768\n",
      "2024-03-19  153.40  154.55  153.00  154.05  154.050    8569789 \n",
      "2024-03-20  154.20  155.30  153.00  153.20  153.200    10080404\n",
      "\n",
      "[243 rows x 6 columns]\n",
      "[[     118.5        118.75       118.2        118.65       114.277\n",
      "   3591870.   ]\n",
      " [     119.45       120.9        119.45       120.9        116.444\n",
      "  14242127.   ]\n",
      " [     120.65       122.3        120.45       121.85       117.359\n",
      "  15532979.   ]\n",
      " ...\n",
      " [     153.         154.5        153.         154.4        154.4\n",
      "  17937768.   ]\n",
      " [     153.4        154.55       153.         154.05       154.05\n",
      "   8569789.   ]\n",
      " [     154.2        155.3        153.         153.2        153.2\n",
      "  10080404.   ]]\n"
     ]
    }
   ],
   "source": [
    "# 設定要使用的特徵\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "# 讀取資料\n",
    "df = pd.read_csv('0050.TW.csv', index_col=0)\n",
    "df = df.round(3)\n",
    "df.index = list(map(lambda x:datetime.datetime.strptime(x, '%Y-%m-%d'), df.index))\n",
    "df.head()\n",
    "\n",
    "\n",
    "print(df)\n",
    "timeseries = df[features].values.round(3)\n",
    "\n",
    "print(timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "eed3caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "EPOCH = 500\n",
    "FEATURES = [ \"Close\"]\n",
    "LABEL =  \"Close\"\n",
    "TRAIN_END=-30\n",
    "DAYS_BEFORE=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "23331894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(df, feature_columns, label_column, train_end=-30, days_before=30, standardize=True):\n",
    "  series = df.copy()\n",
    "  mean = series.mean()\n",
    "  std = series.std()\n",
    "  if standardize:\n",
    "    series = (series - mean)/std\n",
    "\n",
    "  # 划分数据\n",
    "  # 0 ~ train_end 的为训练数据，但实际上，最后的 n 天只是作为 label\n",
    "  # 而 train 中的 label，可用于 test\n",
    "  train_series = series[feature_columns][:train_end]\n",
    "  # 创建训练集\n",
    "  train_feature = pd.DataFrame()\n",
    "  train_label = pd.DataFrame()\n",
    "\n",
    "  # 通过移位，创建历史 days_before 天的数据\n",
    "  for i in range(days_before):\n",
    "    # 当前数据的 7 天前的数据，应该取 开始到 7 天前的数据； 昨天的数据，应该为开始到昨天的数据，如：\n",
    "    # [..., 1,2,3,4,5,6,7] 昨天的为 [..., 1,2,3,4,5,6]\n",
    "    # 比如从 [2:-7+2]，其长度为 len - 7\n",
    "\n",
    "    train_feature['bday%d' % i] = train_series[i: -days_before + i].values.tolist()\n",
    "\n",
    "  # 获取对应的 label\n",
    "  train_label['y'] = series[label_column].to_numpy()[days_before:]\n",
    "  #print(train_data[\"bday4\"])\n",
    "  return train_feature, train_label, df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "22c7d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義模型\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        # 設定輸入尺寸為特徵數量\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=len(features),  # <== 修改：輸入尺寸為 4，表示一天的 4 個特徵\n",
    "            hidden_size=64,\n",
    "            num_layers=1,\n",
    "            batch_first=True)\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(64, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        r_out, (h_n, h_c) = self.lstm(x, None)  # None 表示 hidden state 會用全 0 的 state\n",
    "        out = self.out(r_out[:, -1, :])  # 取最後一天作為輸出\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "00db7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainSet(Dataset):\n",
    "    def __init__(self, data):\n",
    "        # 定义好 image 的路径\n",
    "        # data 取前多少天的数据， label 取最后一天的数据\n",
    "        self.data, self.label = data[:, :-1].float(), data[:, -1].float()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "e35cabe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "getData() got multiple values for argument 'train_end'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23848\\3765015343.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 数据集建立\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_index\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFEATURES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdays_before\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDAYS_BEFORE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTRAIN_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# 获取所有原始数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mall_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLABEL\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 绘制原始数据的图\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: getData() got multiple values for argument 'train_end'"
     ]
    }
   ],
   "source": [
    "# 数据集建立\n",
    "train_feature, train_label, df_index= getData(df, FEATURES, LABEL, days_before=DAYS_BEFORE, train_end=TRAIN_END)\n",
    "# 获取所有原始数据\n",
    "all_series = np.array(df[LABEL].tolist())\n",
    "# 绘制原始数据的图\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(df_index, all_series, label='real-data')\n",
    "# 设置 X 轴的刻度\n",
    "plt.xticks(df_index[::5], pd.to_datetime(df_index[::5]).strftime('%Y/%m/%d'),rotation=45)\n",
    "# 隐藏 X 轴的次刻度\n",
    "plt.minorticks_off()\n",
    "plt.show()\n",
    "\n",
    "# flatern each day in train data\n",
    "train_feature_tensor = torch.Tensor(np.array(train_feature.values.tolist()))\n",
    "train_label_tensor = torch.Tensor(np.array(train_label.values.tolist()))\n",
    "# 创建 dataloader\n",
    "# print(train_feature_tensor)\n",
    "# print(train_label_tensor)\n",
    "train_set = TrainSet(train_feature_tensor, train_label_tensor)\n",
    "# print(train_set.__len__())\n",
    "train_loader = DataLoader(train_set, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "4cab67d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 6, got 7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23848\\1448708441.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# clear gradients for this training step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23848\\2378692040.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mr_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_c\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# None 表示 hidden state 會用全 0 的 state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 取最後一天作為輸出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    765\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    690\u001b[0m                            \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                            ):\n\u001b[1;32m--> 692\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[0;32m    694\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    203\u001b[0m                     expected_input_dim, input.dim()))\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m    206\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m    207\u001b[0m                     self.input_size, input.size(-1)))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 6, got 7"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "rnn = LSTM()\n",
    "if torch.cuda.is_available():\n",
    "    rnn = rnn.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)  # optimize all cnn parameters\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "for step in range(EPOCH):\n",
    "    for tx, ty in train_loader:\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            tx = tx.cuda()\n",
    "            ty = ty.cuda()\n",
    "\n",
    "        output = rnn(tx)\n",
    "        loss = loss_func(torch.squeeze(output), ty)\n",
    "        optimizer.zero_grad()  # clear gradients for this training step\n",
    "        loss.backward()  # back propagation, compute gradients\n",
    "        optimizer.step()\n",
    "\n",
    "    print(step, loss.cpu())\n",
    "    if step % 10:\n",
    "        torch.save(rnn, 'rnn.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1201738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成預測資料\n",
    "generate_data_train = []\n",
    "generate_data_test = []\n",
    "\n",
    "# 測試資料開始的索引\n",
    "test_start = len(all_series) + TRAIN_END\n",
    "\n",
    "# 對所有的資料進行相同的歸一化\n",
    "all_series = (all_series - train_mean) / train_std\n",
    "all_series = torch.Tensor(all_series)\n",
    "\n",
    "for i in range(DAYS_BEFORE, len(all_series)):\n",
    "    x = all_series[i - DAYS_BEFORE:i]\n",
    "    # 將 x 填充到 (bs, ts, is) 中的 timesteps\n",
    "    x = torch.unsqueeze(torch.unsqueeze(x, dim=0), dim=2)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "\n",
    "    y = rnn(x)\n",
    "\n",
    "    if i < test_start:\n",
    "        generate_data_train.append(torch.squeeze(y.cpu()).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb2b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
